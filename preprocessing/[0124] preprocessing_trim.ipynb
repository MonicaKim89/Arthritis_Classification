{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukir\\Documents\\GitHub\\Sign_Recognition\\py\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%cd C:\\Users\\yukir\\Documents\\GitHub\\Sign_Recognition\\py\n",
    "\n",
    "from basic_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukir\\Documents\\Monicas_workspace\\Knee\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\yukir\\Documents\\Monicas_workspace\\Knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    #사이즈\n",
    "    plt.figure(figsize = (10,10))\n",
    "    #xticks/yticks - 눈금표\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    #코랩에서 안돌아감 주의\n",
    "    plt.imshow(img, cmap= 'gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def histogram_equalization(img):\n",
    "    hist, bins = np.histogram(img.flatten(), 256,[0,256])\n",
    "\n",
    "    cdf = hist.cumsum()\n",
    "\n",
    "    # cdf의 값이 0인 경우는 mask처리를 하여 계산에서 제외\n",
    "    # mask처리가 되면 Numpy 계산에서 제외가 됨\n",
    "    # 아래는 cdf array에서 값이 0인 부분을 mask처리함\n",
    "    cdf_m = np.ma.masked_equal(cdf,0)\n",
    "\n",
    "    #History Equalization 공식\n",
    "    cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "\n",
    "    # Mask처리를 했던 부분을 다시 0으로 변환\n",
    "    cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "\n",
    "    img2 = cdf[img]\n",
    "\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \n",
    "img_list = []\n",
    "for i in tqdm (os.listdir(data_path)):\n",
    "    # print(i)\n",
    "    if '.jpg' in i:\n",
    "        # print(i)\n",
    "        img = cv2.imread(data_path+i, cv2.IMREAD_COLOR)\n",
    "        img_list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img5.copy()\n",
    "for i in img_list[:10]:\n",
    "    img = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img2 = clahe.apply(img)\n",
    "    img3 = histogram_equalization(img2)\n",
    "    img4 = clahe.apply(img3)\n",
    "    img5 = histogram_equalization(img3)\n",
    "\n",
    "    img_trim = img5[112-40:112+70, 0:224]\n",
    "\n",
    "    # img_rec = cv2.rectangle(img5, (0, 112-60), (224, 112+70), (255, 0, 255), 2)\n",
    "    show(img_trim)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d93d6df27dcc797823232b994e4f43d959f011089850837812bf48ca3e70a46"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tensorflow37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
