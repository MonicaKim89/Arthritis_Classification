{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukir\\Documents\\GitHub\\Sign_Recognition\\py\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%cd C:\\Users\\yukir\\Documents\\GitHub\\Sign_Recognition\\py\n",
    "\n",
    "from basic_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukir\\Documents\\Monicas_workspace\\Knee\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\yukir\\Documents\\Monicas_workspace\\Knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    #사이즈\n",
    "    plt.figure(figsize = (10,10))\n",
    "    #xticks/yticks - 눈금표\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    #코랩에서 안돌아감 주의\n",
    "    plt.imshow(img, cmap= 'gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def histogram_equalization(img):\n",
    "    hist, bins = np.histogram(img.flatten(), 256,[0,256])\n",
    "\n",
    "    cdf = hist.cumsum()\n",
    "\n",
    "    # cdf의 값이 0인 경우는 mask처리를 하여 계산에서 제외\n",
    "    # mask처리가 되면 Numpy 계산에서 제외가 됨\n",
    "    # 아래는 cdf array에서 값이 0인 부분을 mask처리함\n",
    "    cdf_m = np.ma.masked_equal(cdf,0)\n",
    "\n",
    "    #History Equalization 공식\n",
    "    cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "\n",
    "    # Mask처리를 했던 부분을 다시 0으로 변환\n",
    "    cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "\n",
    "    img2 = cdf[img]\n",
    "\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1495/1495 [00:05<00:00, 284.64it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = 'C:\\\\Users\\\\yukir\\\\Documents\\\\Monicas_workspace\\\\Knee\\\\dataset\\\\knee_dataset_prepro\\\\0\\\\'\n",
    "img_list = []\n",
    "\n",
    "\n",
    "for i in tqdm (os.listdir(data_path)):\n",
    "    # print(i)\n",
    "    if '.jpg' in i:\n",
    "        # print(i)\n",
    "        img = cv2.imread(data_path+i, cv2.IMREAD_COLOR)\n",
    "        img_list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 457/457 [00:01<00:00, 280.67it/s]\n",
      "374it [00:02, 162.13it/s]\n"
     ]
    }
   ],
   "source": [
    "save_path = 'C:\\\\Users\\\\yukir\\\\Documents\\\\Monicas_workspace\\\\Knee\\\\dataset\\\\yolo_data\\\\'\n",
    "data_path = 'C:\\\\Users\\\\yukir\\\\Documents\\\\Monicas_workspace\\\\Knee\\\\dataset\\\\knee_dataset_prepro\\\\4\\\\'\n",
    "\n",
    "\n",
    "img_list = []\n",
    "\n",
    "for i in tqdm (os.listdir(data_path)):\n",
    "    # print(i)\n",
    "    if '.jpg' in i:\n",
    "        # print(i)\n",
    "        img = cv2.imread(data_path+i, cv2.IMREAD_COLOR)\n",
    "        img_list.append(img)\n",
    "\n",
    "\n",
    "for num, i in tqdm (enumerate(img_list)):\n",
    "    num = random.randint(1, len(img_list))\n",
    "    name = os.listdir(data_path)[num]\n",
    "    img = img_list[num]\n",
    "\n",
    "    try: \n",
    "        \n",
    "        img_ = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        img2 = clahe.apply(img_)\n",
    "        img3 = histogram_equalization(img2)\n",
    "        img4 = clahe.apply(img3)\n",
    "        img5 = histogram_equalization(img3)\n",
    "\n",
    "        img_trim = img5[112-40:112+70, 0:224]\n",
    "\n",
    "        cv2.imwrite(save_path+name, img_trim)\n",
    "\n",
    "        if len(os.listdir(save_path)) == 1250:\n",
    "            break\n",
    "\n",
    "\n",
    "    except:\n",
    "       print('error')\n",
    "       continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:\\\\Users\\\\yukir\\\\Documents\\\\Monicas_workspace\\\\Knee\\\\dataset\\\\yolo_data\\\\'\n",
    "\n",
    "file_list = []\n",
    "\n",
    "for i in os.listdir(data_path):\n",
    "    if '.jpg' in i:\n",
    "        file_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1113/1113 [00:01<00:00, 839.56it/s]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C:\\\\Users\\\\yukir\\\\Documents\\\\Monicas_workspace\\\\Knee\\\\dataset\\\\yolo_data\\\\0_9006140L.txt\"\n",
    "\n",
    "for i in tqdm(file_list):\n",
    "    try:\n",
    "        file_name = i.split('.jpg')[0]\n",
    "        shutil.copy2(file_path, data_path+file_name+'.txt')\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d93d6df27dcc797823232b994e4f43d959f011089850837812bf48ca3e70a46"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tensorflow37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
