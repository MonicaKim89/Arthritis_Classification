{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukir\\Documents\\GitHub\\Sign_Recognition\\py\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14192974683001719439\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6635483358035173645\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9883535296\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9707257092248114140\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 993142483275979442\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n",
      "tf 2.2.0\n",
      "keras 2.3.0-tf\n",
      "set_global_determinism(seed=1337) 이거 꼭 해라\n",
      "set_global_determinism(seed=1337) 이거 꼭 해라\n",
      "set_global_determinism(seed=1337) 이거 꼭 해라\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\yukir\\Documents\\GitHub\\Sign_Recognition\\py\n",
    "\n",
    "from basic_preprocessing import *\n",
    "from deeplearning_check import *\n",
    "from machine_learning import *\n",
    "\n",
    "gpu_check()\n",
    "set_global_determinism(seed=SEED)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import math\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from IPython.display import Image\n",
    "\n",
    "#cv\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import math\n",
    "from scipy import ndimage\n",
    "import argparse\n",
    "import imutils\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "#시각화\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import font_manager, rc\n",
    "rc('font',family=\"consolas\")\n",
    "plt.rcParams[\"font.family\"]=\"consolas\" #plt 한글꺠짐\n",
    "plt.rcParams[\"font.family\"]=\"Arial\" #외국어꺠짐\n",
    "plt.rcParams['axes.unicode_minus'] = False # 마이너스 부호 출력 설정\n",
    "plt.rc('figure', figsize=(10,8))\n",
    "\n",
    "sns.set(font=\"consolas\", \n",
    "        rc={\"axes.unicode_minus\":False},style='darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yukir\\Documents\\Monicas_workspace\\Knee\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "from tqdm import tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "%cd C:\\Users\\yukir\\Documents\\Monicas_workspace\\Knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    #사이즈\n",
    "    plt.figure(figsize = (6,6))\n",
    "    #xticks/yticks - 눈금표\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    #코랩에서 안돌아감 주의\n",
    "    plt.imshow(img, cmap= 'gray')\n",
    "    plt.show()\n",
    "\n",
    "def show_img_compar(img_1, img_2 ):\n",
    "    f, ax = plt.subplots(1, 2, figsize=(6,6))\n",
    "    ax[0].imshow(img_1)\n",
    "    ax[1].imshow(img_2)\n",
    "    ax[0].axis('off') #hide the axis\n",
    "    ax[1].axis('off')\n",
    "    f.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL_LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('C:\\\\Users\\\\yukir\\\\Documents\\\\Monicas_workspace\\\\Knee\\\\unet\\\\[0110]knee_annotation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMG_LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    }
   ],
   "source": [
    "# img_loader\n",
    "#Test Image\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "IMG_PATH = 'C:\\\\Users\\\\yukir\\\\Documents\\\\Monicas_workspace\\\\Knee\\\\knee_dataset_org\\\\4\\\\'\n",
    "img_list = []\n",
    "file_name =[]\n",
    "for i in os.listdir(IMG_PATH):\n",
    "    adr = IMG_PATH+i\n",
    "    # print(adr)\n",
    "    img_list.append(IMG_PATH+i)\n",
    "    file_name.append(i)\n",
    "\n",
    "print(len(img_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "295it [00:02, 144.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# img_loader\n",
    "#Test Image\n",
    "\n",
    "X_test = np.zeros((len(img_list),224,224), dtype= np.uint8)\n",
    "\n",
    "sizes_test = []\n",
    "for n, id_ in tqdm(enumerate(img_list)):\n",
    "    img_ = imread(id_)\n",
    "    # show(img)\n",
    "    hist, bins = np.histogram(img_.flatten(), 256,[0,256])\n",
    "\n",
    "    cdf = hist.cumsum()\n",
    "\n",
    "    # cdf의 값이 0인 경우는 mask처리를 하여 계산에서 제외\n",
    "    # mask처리가 되면 Numpy 계산에서 제외가 됨\n",
    "    # 아래는 cdf array에서 값이 0인 부분을 mask처리함\n",
    "    cdf_m = np.ma.masked_equal(cdf,0)\n",
    "\n",
    "    #History Equalization 공식\n",
    "    cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "\n",
    "    # Mask처리를 했던 부분을 다시 0으로 변환\n",
    "    cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "\n",
    "    img = cdf[img_]\n",
    "    # print(img.shape)\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT,IMG_WIDTH), mode = 'constant', preserve_range = True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_test = model.predict(X_test, verbose =1)\n",
    "preds_test_t = (preds_test>0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [00:01<00:00, 240.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm (range (len(preds_test_t))):\n",
    "    img_1 = imread(img_list[i])\n",
    "    img_2 = X_test[i]\n",
    "    img_3 = np.squeeze(preds_test_t[i])\n",
    "\n",
    "    img_name = file_name[i].split('.jpg')[0]\n",
    "\n",
    "    #저장\n",
    "    save_path = 'C:\\\\Users\\\\yukir\\\\Documents\\\\Monicas_workspace\\\\Knee\\\\mask_dataset\\\\4\\\\'\n",
    "    img = cv2.convertScaleAbs(img_3, alpha=(255.0)) # 이거없으면 all black 으로 저장됨 \n",
    "    cv2.imwrite(save_path+img_name+'_mask.jpg', img)\n",
    "\n",
    "    # print(len(preds_test_t)-i, '--------', file_name[i])\n",
    "    # show(preds_test_t[i])\n",
    "    # f, ax = plt.subplots(1, 3, figsize=(8,8))\n",
    "    # ax[0].imshow(img_1,cmap = 'gray')\n",
    "    # ax[1].imshow(img_2,cmap = 'gray')\n",
    "    # ax[2].imshow(img_3,cmap = 'gray')\n",
    "    # ax[0].axis('off') #hide the axis\n",
    "    # ax[1].axis('off')\n",
    "    # ax[2].axis('off')\n",
    "    # f.tight_layout()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d93d6df27dcc797823232b994e4f43d959f011089850837812bf48ca3e70a46"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tensorflow37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
